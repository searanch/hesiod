{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project analyzing works of Ancient Greek Poet Hesiod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Text from Project Gutenberg ."
   ]
  },
  {
   "source": [
    "test this line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is git working?\n"
     ]
    }
   ],
   "source": [
    "print(\"is git working?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open File\n",
    "# DO NOT RUN\n",
    "f = open('hesoid.txt','r', encoding=\"utf8\")\n",
    "raw = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize \n",
    "tokens = nltk.word_tokenize(raw)\n",
    "# Checking lenght\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension\n",
    "tokens_without_sw = [word for word in tokens if not word in stopwords.words('english')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking length to confirm stopwords were removed\n",
    "len(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize sentences\n",
    "sentences = sent_tokenize(raw)\n",
    "#sentences"
   ]
  },
  {
   "source": [
    "PUT sentences in DF\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "# Put tokenized sentences in dataframe\n",
    "\n",
    "Hesiod = DataFrame (sentences,columns=['tokenized_sentences'])\n",
    "Hesiod.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column for lenth of sentences\n",
    "Hesiod[\"len\"] = Hesiod['tokenized_sentences'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulization of sentence lenght\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Hesiod[\"len\"], kde=False)"
   ]
  },
  {
   "source": [
    "# Pre-Processing \n",
    "There are many feature engineering strategies for transforming text data into features. Some involve assigning each unique word-like term to a feature and counting the number of occurrences per training example. However, if we were to perform this strategy right now, we'd end up with an absurd number of features, a result of the myriad possible terms. The classifier would take too long to train and likely overfit. As a result, each NLP problem requires a tailored approach to determine which terms are relevant and meaningful, and this is where we begin our pre-processing.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "can't get contractions installed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Tokenization\n",
    "\n",
    "Step 2: Tokenization\n",
    "\n",
    "In this step, we construct the features. We will begin by breaking apart the corpus into a vocabulary of unique terms, and this is called tokanization.\n",
    "\n",
    "We can tokenize individual terms and generate what's called a bag of words model. You may notice this model has a glaring pitfall: it fails to capture the innate structure of human language. We can also tokenize using nltk, which is the leading platform for building Python programs to work with human language data.\n",
    "\n",
    "We will begin my installing and importing nltk, so we can use it!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hesiod['word_tokens'] = Hesiod['tokenized_sentences'].apply(word_tokenize)\n",
    "Hesiod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hesiod['tokens_no_stopwords']= [word for word in tokens if not word in stopwords.words('english')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lowercase\n",
    "Hesiod['lower'] = Hesiod['word_tokens'].apply(lambda x: [word.lower() for word in x])\n",
    "Hesiod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out punctionation\n",
    "import string\n",
    "punc = string.punctuation\n",
    "Hesiod['no_punc'] = Hesiod['lower'].apply(lambda x: [word for word in x if word not in punc])\n",
    "Hesiod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take outstop words\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "Hesiod['stopwords_removed'] = Hesiod['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "Hesiod.head()\n",
    "\n"
   ]
  },
  {
   "source": [
    "\n",
    "Step 6: Stemming/Lemmatization\n",
    "\n",
    "The idea of stemming is to reduce different forms of word usage into its root word. For example, “drive”, “drove”, “driving”, “driven”, “driver” are derivatives of the word “drive” and very often researchers want to remove this variability from their corpus. Compared to lemmatization, stemming is certainly the less complicated method but it often does not produce a dictionary-specific morphological root of the word. In other words, stemming the word “pies” will often produce a root of “pi” whereas lemmatization will find the morphological root of “pie”.\n",
    "\n",
    "Instead of taking the easy way out with stemming, let’s apply lemmatization to our data but it requires some additional steps compared to stemming. First, we have to apply parts of speech tags, in other words, determine the part of speech (ie. noun, verb, adverb, etc.) for each word.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemminization\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS tagging\n",
    "Hesiod['pos_tags'] = Hesiod['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
    "Hesiod.sample(10)"
   ]
  },
  {
   "source": [
    "We are going to be using NLTK’s word lemmatizer which needs the parts of speech tags to be converted to wordnet’s format. We’ll write a function which make the proper conversion and then use the function within a list comprehension to apply the conversion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hesiod['wordnet_pos'] = Hesiod['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "Hesiod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "Hesiod['lemmatized'] = Hesiod['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "Hesiod.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file!!!!\n",
    "Hesiod.to_csv('Hesoid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write lemonized word to list???\n",
    "\n",
    "lemons = Hesiod['lemmatized'].tolist()\n",
    "lemons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "']\n",
      "['last', 'third', 'opinion', 'prevail']\n",
      "['turned', 'mirth', 'feast', 'believe', 'war', 'end']\n",
      "['time', 'two', 'serpent', 'appear', 'destroyed', 'laocoon', 'one', 'two']\n",
      "['sinon', 'raise', 'fire-signal', 'achaean', 'previously', 'get', 'city', 'pretence']\n",
      "['greek', 'sail', 'tenedos', 'wooden', 'horse', 'come', 'fell', 'upon']\n",
      "['neoptolemus', 'kill', 'priam', 'flee', 'altar', 'zeus', 'herceius', '1']\n",
      "['greek', 'enrage', 'determine', 'stone', 'aias', 'escape', 'danger', 'threaten']\n",
      "['greek', 'burn', 'city', 'sacrifice', 'polyxena', 'tomb', 'achilles', 'odysseus']\n",
      "['demophon', 'acamas', 'find', 'aethra', 'take']\n",
      "['lastly', 'greeks', 'sail', 'away', 'athena', 'plan', 'destroy', 'high']\n",
      "['fragment', '2—dionysus', 'halicarn', 'rom']\n",
      "['antiq']\n",
      "[]\n",
      "['68', 'accord', 'arctinus', 'one', 'palladium', 'give', 'dardanus', 'zeus']\n",
      "['hidden', 'secret', 'place', 'copy', 'make', 'resemble', 'original', 'point']\n",
      "['copy', 'achaean', 'take', 'result', 'plot']\n",
      "['fragment', '3—scholiast', 'euripedes', 'andromache', '10', 'cyclic', 'poet', 'compose']\n",
      "['fragment', '4—scholiast', 'euripedes', 'troades', '31', 'follower', 'acamus', 'demophon']\n",
      "['lysimachus', 'however', 'say', 'author', '_sack_', 'write', 'follow', '‘']\n",
      "['515', 'say', 'praise', '3201', 'apply', 'physician', 'generally', 'machaon']\n",
      "['arctinus', '_sack', 'ilium_', 'seem', 'opinion', 'say']\n",
      "['1-8', '‘', 'father', 'famous', 'earth-shaker', 'give', 'gift', 'make']\n",
      "['one', 'give', 'hand', 'light', 'draw', 'cut', 'missile', 'flesh']\n",
      "['first', 'notice', 'aias', '’', 'flash', 'eye', 'cloud', 'mind']\n",
      "[]\n",
      "['477', '‘', 'iambus', 'stand', 'little', 'astride', 'foot', 'advance']\n",
      "['content', 'follow']\n",
      "['athena', 'cause', 'quarrel', 'agamemnon', 'menelaus', 'voyage', 'troy']\n",
      "['agamemnon', 'stay', 'appease', 'anger', 'athena']\n",
      "['diomedes', 'nestor', 'put', 'sea', 'get', 'safely', 'home']\n",
      "['menelaus', 'set', 'reach', 'egypt', 'five', 'ship', 'rest', 'destroy']\n",
      "['calchas', 'leontes', 'polypoetes', 'go', 'land', 'colophon', 'bury', 'teiresias']\n",
      "['agamemnon', 'follower', 'sail', 'away', 'ghost', 'achilles', 'appear', 'tried']\n",
      "['storm', 'rock', 'call', 'capherides', 'describe', 'end', 'locrian', 'aias']\n",
      "['neoptolemus', 'warn', 'thetis', 'journey', 'overland', 'come', 'thrace', 'meet']\n",
      "['recognize', 'peleus', 'reach', 'molossi']\n",
      "['come', 'murder', 'agamemnon', 'aegisthus', 'clytaemnestra', 'follow', 'vengeance', 'orestes']\n",
      "['finally', 'menelaus', 'return', 'home']\n",
      "['fragment', '2—argument', 'euripides', 'medea', '‘', 'forthwith', 'medea', 'make']\n",
      "['2', 'story', 'go', 'heracles', 'besiege', 'themiscyra', 'thermodon', 'could']\n",
      "['hegias', 'give', 'account', 'poem']\n",
      "['fragment', '4—eustathius', '1796']\n",
      "['45', 'colophonian', 'author', '_returns_', 'say', 'telemachus', 'afterwards', 'marry']\n",
      "['fragment', '5—clement', 'alex']\n",
      "['strom.', 'vi']\n",
      "['2']\n",
      "['12']\n",
      "['8', '‘', 'gift', 'beguile', 'men', '’', 'mind', 'deed']\n",
      "['28']\n",
      "['7', 'poetry', 'homer', '_returns_—for', 'account', 'hades', 'terror', 'there—know']\n",
      "['athenaeus', '281', 'b', 'writer', '“', 'return', 'atreidae', '”']\n",
      "['man', 'immoderately', 'give', 'pleasure', 'ask', 'life', 'like', 'god']\n",
      "['zeus', 'annoy', 'fulfil', 'prayer', 'promise', 'prevent', 'enjoy', 'pleasure']\n",
      "['telegony', 'fragment', '1—proclus', 'chrestomathia', 'ii', '_returns_', 'come', '_odyssey_']\n",
      "['suitor', 'penelope', 'bury', 'kinsman', 'odysseus', 'sacrifice', 'nymphs', 'sail']\n",
      "['entertain', 'polyxenus', 'receive', 'mix', 'bowl', 'gift', 'story', 'trophonius']\n",
      "['next', 'sail', 'back', 'ithaca', 'performs', 'sacrifice', 'order', 'teiresias']\n",
      "['war', 'break', 'thesprotians', 'lead', 'odysseus', 'brygi']\n",
      "['are', 'rout', 'army', 'odysseus', 'athena', 'engages', 'ares', 'apollo']\n",
      "['death', 'callidice', 'polypoetes', 'son', 'odysseus', 'succeed', 'kingdom', 'odysseus']\n",
      "['meantime', 'telegonus', 'travel', 'search', 'father', 'land', 'ithaca', 'ravage']\n",
      "['telegonus', 'learn', 'mistake', 'transport', 'father', '’', 'body', 'penelope']\n",
      "['fragment', '2—eustathias', '1796']\n",
      "['35', 'author', '_telegony_', 'cyrenaean', 'relates', 'odysseus', 'calypso', 'son']\n",
      "['homerica', 'expedition', 'amphiaraus', 'fragment', '1—pseudo-herodotus', 'life', 'homer', 'sit']\n",
      "['take', 'oechalia', 'fragment', '1—eustathius', '330']\n",
      "['41', 'account', 'give', 'eurytus', 'daughter', 'iole', 'whose', 'sake']\n",
      "['homer', 'also', 'seem', 'write', 'subject', 'historian', 'show', 'relate']\n",
      "['however', 'assert', 'opposite', 'creophylus', 'write', 'poem', 'homer', 'lent']\n",
      "['callimachus', 'write', '‘', 'work', 'samian', 'receive', 'divine', 'homer']\n",
      "['sing', 'eurytus', 'woe', 'golden-haired', 'ioleia', 'repute', 'one', 'homer']\n",
      "['dear', 'heaven']\n",
      "['great', 'honour', 'creophylus', '’', 'fragment', '2—cramer', 'anec']\n",
      "['oxon']\n",
      "[]\n",
      "['327', '‘', 'rag', 'garment', 'even', 'see.', '’', 'verse']\n",
      "['343', 'shall', 'also', 'find', '_taking', 'oechalia_']\n",
      "['fragment', '3—scholaist', 'sophocles', 'trach.', '266', 'disagreement', 'number', 'son']\n",
      "['hesiod', 'say', 'eurytus', 'antioche', 'many', 'four', 'son', 'creophylus']\n",
      "['fragment', '4—scholiast', 'euripides', 'medea', '273', 'didymus', 'contrast', 'follow']\n",
      "['however', 'since', 'son', 'young', 'go', 'along', 'left', 'altar']\n",
      "['relative', 'creon', 'kill', 'spread', 'story', 'medea', 'kill', 'child']\n",
      "['phocais', 'fragment', '1—pseudo-herodotus', 'life', 'homer', 'live', 'thestorides', 'homer']\n",
      "['margites', 'fragment', '1—suidas', 's.v']\n",
      "['pigres']\n",
      "['carian', 'halicarnassus', 'brother', 'artemisia', 'wife', 'mausolus', 'distinguished', 'war']\n",
      "['fragment', '2—atilius', 'fortunatianus', 'p.', '286', 'keil', '‘', 'come']\n",
      "['dear', 'hand', 'hold', 'sweet-toned', 'lyre.', '’', 'fragment', '3—plato']\n",
      "['ii']\n",
      "['p.', '147', '‘', 'know', 'many', 'thing', 'know', 'badly']\n",
      "['eth']\n",
      "['vi']\n",
      "['7', '1141', '‘', 'god', 'teach', 'neither', 'dig', 'plough']\n",
      "['160', 'refers', 'margites', 'man', 'though', 'well', 'grow', 'know']\n",
      "['fragment', '5—zenobius', 'v.', '68', '‘', 'fox', 'know', 'many']\n",
      "['cercopes']\n",
      "['two', 'brother', 'live', 'upon', 'earth', 'practise', 'every', 'kind']\n",
      "['call', 'cercopes', '3501', 'cunning', 'doings', 'one', 'name', 'passalus']\n",
      "['mother', 'daughter', 'memnon', 'see', 'trick', 'tell', 'keep', 'clear']\n",
      "['cercopes', 'son', 'theia', 'ocean', 'say', 'turned', 'stone', 'try']\n",
      "['‘', 'liar', 'cheat', 'skilled', 'deed', 'irremediable', 'accomplished', 'knave']\n",
      "['far', 'world', 'roam', 'deceive', 'men', 'wander', 'continually.', '’']\n",
      "['1-8', 'begin', 'first', 'pray', 'choir', 'muse', 'come', 'helicon']\n",
      "['fain', 'would', 'sound', 'men', '’', 'ear', 'awful', 'strife']\n",
      "['thus', 'war', 'begin']\n",
      "[]\n",
      "['9-12', 'one', 'day', 'thirsty', 'mouse', 'escape', 'ferret', 'dangerous']\n",
      "['loud-voiced', 'pond-larker', 'spy', 'uttered', 'word']\n",
      "[]\n",
      "['13-23', '‘', 'stranger']\n",
      "['whence', 'come', 'shore', 'begot']\n",
      "['tell', 'truly', 'let', 'find', 'lie']\n",
      "['find', 'worthy', 'friend', 'take', 'house', 'give', 'many', 'noble']\n",
      "['king', 'puff-jaw', 'honour', 'pond', 'ruler', 'frog', 'continually']\n",
      "['father', 'bring', 'mud-man', 'mat', 'waterlady', 'bank', 'eridanus']\n",
      "['see', 'indeed', 'well-looking', 'stouter', 'ordinary', 'sceptred', 'king', 'warrior']\n",
      "['24-55', 'crumb-snatcher', 'answer', 'say', '‘', 'ask', 'race', 'well-known']\n",
      "['crumb-snatcher', 'call', 'son', 'bread-nibbler—he', 'stout-hearted', 'father—and', 'mother', 'quern-licker']\n",
      "['make', 'friend', 'altogether', 'different', 'nature']\n",
      "['get', 'living', 'water', 'use', 'food', 'men', 'never', 'miss']\n",
      "['battle', 'never', 'flinch', 'cruel', 'onset', 'plunge', 'straight', 'fray']\n",
      "['fear', 'man', 'though', 'big', 'body', 'run', 'along', 'bed']\n",
      "['two', 'thing', 'fear', 'else', 'whole', 'world', 'hawk', 'ferret—for']\n",
      "['fear', 'ferret', 'keener', 'sort', 'follow', 'still', 'even', 'dive']\n",
      "['3601', 'gnaw', 'radish', 'cabbage', 'pumpkin', 'fee', 'green', 'leek']\n",
      "['56-64', 'puff-jaw', 'answer', 'smile', '‘', 'stranger', 'boast', 'much']\n",
      "['son', 'chronos', 'give', 'u', 'frogs', 'power', 'lead', 'double']\n",
      "['would', 'learn', 'thing', '’', 'ti', 'easy', 'do', 'mount']\n",
      "['65-81', 'say', 'offer', 'back']\n",
      "['mouse', 'mount', 'put', 'paw', 'upon', '’', 'sleek', 'neck']\n",
      "['first', 'still', 'saw', 'land', 'near', 'pleased', 'delighted', 'puff-jaw']\n",
      "['put', 'tail', 'upon', 'water', 'work', 'like', 'steer', 'oar']\n",
      "['dark', 'wave', 'wash', 'cried', 'aloud', 'say', '‘', 'wise']\n",
      "['82-92', 'suddenly', 'water-snake', 'appeared', 'horrid', 'sight', 'alike', 'hold']\n",
      "['saw', 'puff-jaw', 'dive', 'never', 'think', 'helpless', 'friend', 'would']\n",
      "['mouse', 'desert', 'fell', 'back', 'water']\n",
      "['wrung', 'paw', 'squeak', 'agony', 'death', 'many', 'time', 'sank']\n",
      "['could', 'escape', 'doom', 'wet', 'fur', 'weigh', 'heavily']\n",
      "['last', 'dying', 'utter', 'word']\n",
      "[]\n",
      "['93-98', '‘', 'ah', 'puff-jaw', 'shall', 'go', 'unpunished', 'treachery']\n",
      "['threw', 'castaway', 'body', 'rock']\n",
      "['vile', 'coward']\n",
      "['land', 'would', 'better', 'man', 'box', 'wrestle', 'run', 'trick']\n",
      "['heaven', 'avenge', 'eye', 'surely', 'host', 'mouse', 'punish', 'let']\n",
      "['99-109', 'word', 'breathe', 'soul', 'upon', 'water']\n",
      "['lick-platter', 'sit', 'upon', 'soft', 'bank', 'saw', 'die', 'raise']\n",
      "['heard', 'fate', 'mouse', 'seize', 'fierce', 'anger', 'bid', 'herald']\n",
      "['mouse', 'come', 'haste', 'dawn', 'bread-nibbler', 'stand', 'first', 'enrage']\n",
      "[]\n",
      "['110-121', '‘', 'friend', 'even', 'alone', 'suffer', 'great', 'wrong']\n",
      "['pitiable', 'lose', 'three', 'son']\n",
      "['first', 'abhor', 'ferret', 'seize', 'kill', 'one', 'catch', 'outside']\n",
      "['third', 'dear', 'mother', 'love', 'well', 'puff-jaw', 'carry', 'deep']\n",
      "['come', 'let', 'u', 'arm', 'go', 'arrayed', 'rich-wrought', 'arms.']\n",
      "['122-131', 'word', 'persuade', 'gird']\n",
      "['are', 'charge', 'war', 'equip']\n",
      "['first', 'fasten', 'greave', 'cover', 'shin', 'green', 'bean-pods', 'break']\n",
      "['breast', 'plate', 'skin', 'stretch', 'reed', 'skilfully', 'make', 'ferret']\n",
      "['shield', 'centre-piece', 'lamp', 'spear', 'long', 'needle', 'bronze', 'work']\n",
      "[]\n",
      "['132-138', 'mouse', 'arm']\n",
      "['frog', 'aware', 'rise', 'water', 'come', 'together', 'one', 'place']\n",
      "['ask', 'whence', 'quarrel', 'arise', 'cause', 'anger', 'herald', 'draw']\n",
      "['bring', 'grim', 'message', 'war', 'speaking', 'thus']\n",
      "['139-143', '‘', 'frog', 'mice', 'send', 'threat', 'bid', 'arm']\n",
      "['fight', 'many', 'warrior', 'among', 'frogs.', '’']\n",
      "['144-146', 'word', 'explain', 'matter']\n",
      "['blameless', 'speech', 'come', 'ear', 'proud', 'frog', 'disturb', 'heart']\n",
      "['rise', 'say']\n",
      "['147-159', '‘', 'friend', 'kill', 'mouse', 'see', 'one', 'perish']\n",
      "['surely', 'drown', 'play', 'lake', 'imitate', 'swim', 'frog', 'wretch']\n",
      "['come', 'let', 'u', 'take', 'counsel', 'may', 'utterly', 'destroy']\n",
      "['moreover', 'tell', 'think', 'best']\n",
      "['let', 'u', 'gird', 'armour', 'take', 'stand', 'brink', 'lake']\n",
      "['160-167', 'speech', 'persuade', 'arm']\n",
      "['covered', 'shin', 'leaf', 'mallow', 'breastplate', 'make', 'fine', 'green']\n",
      "['one', 'equip', 'long', 'pointed', 'rush', 'spear', 'smooth', 'snail-shells']\n",
      "['stand', 'close-locked', 'rank', 'upon', 'high', 'bank', 'wave', 'spear']\n",
      "[]\n",
      "['168-173', 'zeus', 'call', 'god', 'starry', 'heaven', 'show', 'martial']\n",
      "['ask', 'sly', 'smile', '‘', 'deathless', 'god', 'help', 'frog']\n",
      "['174-176', '‘', 'daughter', 'go', 'aid', 'mouse']\n",
      "['frolic', 'temple', 'continually', 'delight', 'fat', 'sacrifice', 'kind', 'food.']\n",
      "['177-196', 'say', 'son', 'cronos']\n",
      "['athena', 'answer', '‘', 'would', 'never', 'go', 'help', 'mice']\n",
      "['thing', 'do', 'vexes', 'heart', 'exceedingly', 'eaten', 'hole', 'sacred']\n",
      "['money-lender', 'charge', 'interest', 'bitter', 'thing', 'immortal']\n",
      "['borrow', 'weave', 'nothing', 'repay']\n",
      "['yet', 'even', 'help', 'frog', 'also', 'considerable', 'return', 'early']\n",
      "['god', 'let', 'u', 'refrain', 'help', 'host', 'one', 'u']\n",
      "['let', 'u', 'rather', 'amuse', 'watch', 'fight', 'heaven.', '’']\n",
      "['197-198', 'say', 'athena']\n",
      "['god', 'agree', 'go', 'body', 'one', 'place']\n",
      "[]\n",
      "['199-201', 'gnat', 'great', 'trumpet', 'sound', 'fell', 'note', 'war']\n",
      "[]\n",
      "['202-223', 'first', 'loud-croaker', 'wound', 'lickman', 'belly', 'right', 'midriff']\n",
      "['fell', 'face', 'soil', 'soft', 'fur', 'dust', 'fell', 'thud']\n",
      "['next', 'troglodyte', 'shot', 'son', 'mudman', 'drive', 'strong', 'spear']\n",
      "['beety', 'strike', 'pot-visitor', 'heart', 'kill', 'bread-nibbler', 'hit', 'loud-crier']\n",
      "['pond-larker', 'saw', 'loud-crier', 'perishing', 'struck', 'quickly', 'wound', 'troglodyte']\n",
      "['thereat', 'ocimides', 'seize', 'grief', 'struck', 'sharp', 'reed', 'draw']\n",
      "['lickman', 'shot', 'bright', 'spear', 'hit', 'unerringly', 'midriff']\n",
      "['mark', 'cabbage-eater', 'run', 'away', 'fell', 'steep', 'bank', 'yet']\n",
      "['also', 'slew', 'cheese-eater', 'brink', '...', 'lacuna']\n",
      "['224-251', 'reedy', 'take', 'flight', 'saw', 'ham-nibbler', 'flee', 'plunge']\n",
      "['blameless', 'pot-visitor', 'kill', 'brewer', 'water-larked', 'kill', 'lord', 'ham-nibbler']\n",
      "['faultless', 'muck-coucher', 'sprang', 'upon', 'lick-platter', 'kill', 'spear', 'brought']\n",
      "['crumb-snatcher', 'fight', 'avenge', 'dead', 'comrade', 'hit', 'leeky', 'reach']\n",
      "['see', 'cabbage-climber', 'take', 'clod', 'mud', 'hurl', 'mouse', 'plaster']\n",
      "['thereat', 'crumb-snatcher', 'enrage', 'caught', 'strong', 'hand', 'huge', 'stone']\n",
      "['croakperson', 'keep', 'rush', 'mouse', 'turn', 'hit', 'middle', 'belly']\n",
      "['troglodyte', 'saw', 'deed', 'limp', 'away', 'fight', 'river', 'bank']\n",
      "['bread-nibbler', 'hit', 'puff-jaw', 'toes—he', 'come', 'last', 'lake', 'greatly']\n",
      "['252-259', 'leeky', 'saw', 'fall', 'forward', 'still', 'half', 'alive']\n",
      "['noble', 'rueful', 'like', 'are', 'struck', 'flawless', 'head-piece', 'make']\n",
      "['saw', 'rush', 'stay', 'meet', 'stout-hearted', 'hero', 'dive', 'depth']\n",
      "[]\n",
      "['260-271', 'one', 'among', 'mice', 'slice-snatcher', 'excel', 'rest', 'dear']\n",
      "['go', 'house', 'bade', 'son', 'take', 'part', 'war']\n",
      "['warrior', 'threaten', 'destroy', 'race', 'frog', 'utterly', '3603', 'split']\n",
      "['shook', 'head', 'utter', 'word']\n",
      "['272-276', '‘', 'dear', 'dear', 'fearful', 'deed', 'eye', 'behold']\n",
      "['slice-snatcher', 'make', 'small', 'panic', 'rush', 'fro', 'among', 'frog']\n",
      "['let', 'u', 'make', 'haste', 'send', 'warlike', 'pallas', 'even']\n",
      "['277-284', 'say', 'son', 'cronos', 'hera', 'answer', '‘', 'son']\n",
      "['rather', 'come', 'let', 'u', 'go', 'help', 'else', 'let']\n",
      "['285-293', 'say', 'hera', 'son', 'cronos', 'cast', 'lurid', 'thunderbolt']\n",
      "['thus', 'frighten', 'frogs', 'mouse', 'alike', 'hurl', 'bolt', 'upon']\n",
      "['yet', 'even', 'army', 'mouse', 'relax', 'hop', 'still', 'destroy']\n",
      "['son', 'cronos', 'olympus', 'pitied', 'frog', 'straightway', 'send', 'helper']\n",
      "[]\n",
      "['294-303', 'come', 'suddenly', 'warrior', 'mail', 'back', 'curve', 'claw']\n",
      "['also', 'eight', 'leg', 'two', 'feelers—persistent', 'creature', 'call', 'crab']\n",
      "['nip', 'tail', 'paws', 'foot', 'mice', 'jaw', 'spear', 'beat']\n",
      "['mouse', 'afraid', 'longer', 'stand', 'turn', 'fled']\n",
      "['already', 'sun', 'set', 'come', 'end', 'one-day', 'war']\n",
      "['origin', 'homer', 'hesiod', 'contest', 'everyone', 'boast', 'divine', 'poet']\n",
      "['hesiod', 'indeed', 'put', 'name', 'native', 'place', 'prevent', 'rivalry']\n",
      "['foremost', 'men', 'smyrna', 'say', 'son', 'meles', 'river', 'town']\n",
      "['name', 'homer', 'later', 'become', 'blind', 'usual', 'epithet', 'people']\n",
      "['chians', 'hand', 'bring', 'forward', 'evidence', 'show', 'countryman', 'say']\n",
      "['colophonians', 'even', 'show', 'place', 'declare', 'begin', 'compose', 'schoolmaster']\n",
      "['parent', 'also', 'hand', 'great', 'disagreement']\n",
      "['hellanicus', 'cleanthes', 'say', 'father', 'maeon', 'eugaeon', 'say', 'meles']\n",
      "['say', 'son', 'thamyras', 'egyptian', 'say', 'menemachus', 'priest-scribe', 'even']\n",
      "['mother', 'variously', 'call', 'metis', 'cretheis', 'themista', 'eugnetho']\n",
      "['others', 'say', 'ithacan', 'woman', 'sell', 'slave', 'phoenician', 'calliope']\n",
      "['homer', 'call', 'meles', 'accord', 'different', 'account', 'melesigenes', 'altes']\n",
      "['authority', 'say', 'call', 'homer', 'father', 'give', 'hostage', 'persian']\n",
      "['set', 'however', 'hear', 'say', 'pythia', 'concern', 'homer', 'time']\n",
      "['monarch', 'inquire', 'city', 'homer', 'come', 'whose', 'son', 'priestess']\n",
      "['ithaca', 'country', 'telemachus', 'father', 'epicasta', 'nestor', '’', 'daughter']\n",
      "['say', 'early', 'hesiod', 'others', 'young', 'akin']\n",
      "['give', 'descent', 'thus', 'apollo', 'aethusa', 'daughter', 'poseidon', 'son']\n",
      "['pierus', 'nymph', 'methone', 'sprang', 'oeager', 'oeager', 'calliope', 'orpheus']\n",
      "['descent', 'continue', 'iadmonides', 'philoterpes', 'euphemus', 'epiphrades', 'melanopus', 'son']\n",
      "['dius', 'pycimede', 'daughter', 'apollo', 'two', 'son', 'hesiod', 'perses']\n",
      "['accord', 'one', 'account', 'flourish', 'time', 'even', 'contest', 'skill']\n",
      "['say', 'homer', 'compose', '_margites_', 'go', 'city', 'city', 'minstrel']\n",
      "['pythia', 'answer', '‘', 'isle', 'io', 'mother', '’', 'country']\n",
      "['time', 'ganyctor', 'celebrate', 'funeral', 'rite', 'father', 'amphidamas', 'king']\n",
      "['story', 'go', 'two', 'go', 'chalcis', 'meet', 'chance']\n",
      "['leading', 'chalcidians', 'judge', 'together', 'paneides', 'brother', 'dead', 'king']\n",
      "['hesiod', 'begin', '‘', 'homer', 'son', 'meles', 'inspire', 'wisdom']\n",
      "['hesiod', 'however', 'annoy', 'homer', '’', 'felicity', 'hurry', 'pose']\n",
      "['therefore', 'begin', 'follow', 'line', '‘', 'come', 'muse', 'sing']\n",
      "['first', 'follow', 'verse', 'hesiod', '’', 'next', 'homer', '’']\n",
      "['hesiod', '‘', 'din', 'flesh', 'ox', 'horse', '’', 'necks—']\n",
      "['man', 'standard', 'answer']\n",
      "['man', 'standard', 'excellent', 'good', 'bad', 'bad', 'thing']\n",
      "['ask', 'whatever', 'else', 'heart', 'desires.', '’', 'hesiod', '‘']\n",
      "['king', 'paneides', 'bid', 'recite', 'fine', 'passage', 'poem']\n",
      "['hesiod', 'therefore', 'begin', 'follow', '‘', 'pleiads', 'daughter', 'atlas']\n",
      "['forty', 'night', 'day', 'hidden', 'appear', 'year', 'wear', 'round']\n",
      "['law', 'plain', 'dwell', 'near', 'sea', 'live', 'rich-soiled', 'valley']\n",
      "['choose', 'best', 'awaited', 'charge', 'trojan', 'noble', 'hector', 'make']\n",
      "['shield', 'close', 'shield', 'helm', 'helm', 'man', 'fellow', 'peak']\n",
      "['murderous', 'battle', 'bristle', 'long', 'flesh-rending', 'spear', 'hold', 'flash']\n",
      "['hard', 'heart', 'would', 'could', 'see', 'strife', 'joy', 'felt']\n",
      "['king', 'give', 'crown', 'hesiod', 'declare', 'right', 'call', 'upon']\n",
      "['way', 'tell', 'hesiod', 'gain', 'victory', 'receive', 'brazen', 'tripod']\n",
      "['say', 'approach', 'temple', 'prophetess', 'become', 'inspire', 'say', '‘']\n",
      "['beware', 'pleasant', 'grove', 'nemean', 'zeus', 'death', '’', 'end']\n",
      "['continued', 'stay', 'somewhat', 'long', 'time', 'oenoe', 'young', 'men']\n",
      "['third', 'day', 'however', 'body', 'brought', 'land', 'dolphins', 'local']\n",
      "['thereupon', 'people', 'hurry', 'shore', 'recognize', 'body', 'lament', 'buried']\n",
      "['fear', 'anger', 'countryman', 'launch', 'fish', 'boat', 'put', 'sea']\n",
      "['eratosthenes', 'however', 'say', '“', 'hesiod', '”', 'ctimenus', 'antiphus']\n",
      "['add', 'girl', 'sister', 'above-named', 'hang', 'seduce', 'seduced', 'stranger']\n",
      "['later', 'time', 'men', 'orchomenus', 'remove', 'body', 'direct', 'oracle']\n",
      "['homer', 'lose', 'victory', 'go', 'place', 'place', 'recite', 'poem']\n",
      "['xanthus', 'gorgus', 'son', 'midas', 'king', 'heard', 'epic', 'invite']\n",
      "['write', 'follow', 'line', '—', '‘', 'maiden', 'bronze', 'sit']\n",
      "['water', 'flow', 'tall', 'tree', 'put', 'forth', 'leaf', 'river']\n",
      "['delphi', 'tell', 'go', 'athens', 'entertain', 'medon', 'king', 'athenian']\n",
      "['one', 'day', 'council', 'hall', 'cold', 'fire', 'burning', 'draw']\n",
      "['blaze', 'fire', 'house', 'look', 'worthy', 'upon', 'wintry', 'day']\n",
      "['next', 'go', 'argos', 'recite', 'verse', '_iliad_', '‘', 'son']\n",
      "['two', 'go', 'third', 'leader', 'eurypylus', 'godlike', 'man', 'son']\n",
      "['men', 'eighty', 'dark', 'ship', 'wherein', 'range', 'men', 'skilled']\n",
      "['inscription', 'cut', 'upon', 'statue', '‘', 'divine', 'homer', 'sweet-voiced']\n",
      "['cause', 'people', 'great', 'city', 'set', 'statue', 'serve', 'honour']\n",
      "['poet', 'sail', 'io', 'assembly', 'break', 'join', 'creophylus', 'stay']\n",
      "['say', 'sit', 'sea', 'ask', 'boy', 'return', 'fishing', '‘']\n",
      "['explain', 'catch', 'nothing', 'fishing', 'catch', 'lice', 'louse', 'caught']\n",
      "['hereupon', 'homer', 'remember', 'oracle', 'perceive', 'end', 'life', 'come']\n",
      "['retire', 'place', 'slip', 'clayey', 'place', 'fell', 'upon', 'side']\n",
      "['bury', 'io', 'epitaph', '‘', 'earth', 'cover', 'sacred', 'head']\n"
     ]
    }
   ],
   "source": [
    "for i in lemons:\n",
    "    print(i[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-9ae0acf2eed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\LizPy\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    550\u001b[0m         '''\n\u001b[0;32m    551\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\LizPy\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    635\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fast path when counter is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                 \u001b[0m_count_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(lemons).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lemons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# for loop\n",
    "\n",
    "for i in lemons:\n",
    "   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}